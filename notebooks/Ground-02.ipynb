{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground & ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One use case we have been exploring as a part of the Ground agenda recently is managing the lifecycles of machine learning models using Ground. In particular, we are interested in tracking the code and the data combined to output a particular model. As we've already learned, Ground treats versioning as a first-class citizen. As a result, it is easy to imagine a scenario in which Ground would help users track which particular version of data was used to train a model for reproducibility purposes. \n",
    "\n",
    "As an aside, it is an interesting and open research question how we track and version datasets. We're first going to initialize the tutorial. Run the cell below this before moving on because it takes a minute to set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ml import tutorial\n",
    "tutorial.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular example, we will be toying with a model that predicts the location of a Twitter user based on the content of the tweet. Below is a rough description of the pipeline that we have put together:\n",
    "\n",
    "1. Tweets are crawled from Twitter to generate a training set and a test set.\n",
    "2. Those tweets are cleaned and normalized.\n",
    "3. The model is trained on the cleaned training set. \n",
    "4. The model trained in step 3 is validated on the cleaned testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model training pipeline](ml/target_test_simple.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a part of these exercises, we have pre-built a number of helper functions that you might find useful as you go through the steps below. Make sure you read the tutorial helper function descriptions below before continuing.\n",
    "\n",
    "* `setup`: prepares and configures the system and data for this tutorial\n",
    "* `display_data`: displays a dataframe containing the data we will use throughout this tutorial; this data is the pre-labeled training & test data that we are going to use to train the model. There are some funny tweets for you to browse through. :-)\n",
    "* `get_ground_metadata`: queries ground and displays all relevant metadata for this tutorial\n",
    "* `test_model`: executes the machine learning pipeline to train and test a model, reports prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tutorial.display_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = tutorial.test_model()\n",
    "print(output.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we have a baseline model, and it does pretty well! The default case would be to guess the United States, asbout 35% of tweets come from the US. We're clearly doing a good bit better than that. However, we're not satisfied with this quite yet; we'd like to improve this, and we have a guess that improving the cleaning process will help improve our model accuracy. We've set up the skeleton of a `clean` function below for you to fill in. You're welcome to try anything you'd like to improve the cleaning process!\n",
    "\n",
    "For those who might be less familiar with data cleaning and ETL, here's a simple suggestion and code snippet that you can try out in the cell below. You're welcome to modify it as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile ml/my_cleaner.py\n",
    "\n",
    "# TODO: There should be more here. \"Simple heuristic: It gets better if you...\" do what? \n",
    "# Give them a menu of things to try.\n",
    "\n",
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import HTMLParser\n",
    "import preprocessor as tweet_preprocessor\n",
    "html_parser = HTMLParser.HTMLParser()\n",
    "\n",
    "def clean(df):\n",
    "    df[\"tweet\"].apply(html_parser.unescape)\n",
    "    df[\"tweet\"].apply(tweet_preprocessor.tokenize)\n",
    "    # and so on...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we wrote the data cleaning function above but didn't have time to test or deploy it. A week later, you come back to it and run the model with the same script again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = tutorial.test_model()\n",
    "print(output.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it seems like something has changed pretty significantly. We've gone from 60% accuracy down to 35%. It's very likely that something outside of what we control has changed, causing the sudden drop from fairly accurate to no-better-than-random.\n",
    "\n",
    "The question we have to answer next is what changed that caused our pipeline to break. We can come up with a long list of things that might have broken. If you're stuck, we've written a description below that will help walk you through the investigative steps. \n",
    "\n",
    "**HINTS**: \n",
    "\n",
    "1. You're probably going to find the tutorial helper functions described above above very helpful.\n",
    "2. The ultimate solution will be to modify the `clean` function somehow. We provided a skeleton below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your experiments and exploration go here. \n",
    "# The cells below are meant to be for extra commands. You don't necessarily need to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your experiments and exploration go here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your experiments and exploration go here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your experiments and exploration go here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile ml/my_cleaner.py\n",
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean(df):\n",
    "    pass\n",
    "    # your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANOTHER HINT**: We suggest you start off by looking at the metadata stored in Ground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The model should now be back to normal.\n",
    "output = tutorial.test_model()\n",
    "print(output.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full solution is provided [here]()(***TODO***: Add link to notebook with full solution.)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
